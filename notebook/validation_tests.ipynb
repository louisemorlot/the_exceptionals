{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0cbbee-9f75-4806-a2e4-9b1b925b1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Union, List, Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import no_grad, cuda\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms.v2 as transforms_v2\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/localscratch/project/the_exceptionals/model\")\n",
    "from unet import UNet\n",
    "\n",
    "sys.path.append(\"/localscratch/project/the_exceptionals/util/\")\n",
    "from visualize import show_random_dataset_image_with_prediction\n",
    "\n",
    "sys.path.append(\"/localscratch/project/the_exceptionals/data/\")\n",
    "#from local import (\n",
    "#    CellDataset,\n",
    "#    show_random_dataset_image,\n",
    "#    show_one_image\n",
    "#)\n",
    "import local\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5231a36-1182-4ca4-ac70-a1002a866ebd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.uint16. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m img_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/localscratch/project/data2d/norm_img/val/images/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m mask_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/localscratch/project/data2d/val_images2D/masks/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m testData \u001b[38;5;241m=\u001b[39m \u001b[43mlocal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTestDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localscratch/project/the_exceptionals/data/local.py:147\u001b[0m, in \u001b[0;36mTestDataset.__init__\u001b[0;34m(self, img_dir, mask_dir)\u001b[0m\n\u001b[1;32m    144\u001b[0m img_crops \u001b[38;5;241m=\u001b[39m img_tensor\u001b[38;5;241m.\u001b[39munfold(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcropsize, slide)\u001b[38;5;241m.\u001b[39munfold(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcropsize, slide)\n\u001b[1;32m    145\u001b[0m img_crops\u001b[38;5;241m.\u001b[39munsqueeze(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m mask_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# dim H, W\u001b[39;00m\n\u001b[1;32m    148\u001b[0m mask_crops \u001b[38;5;241m=\u001b[39m mask_tensor\u001b[38;5;241m.\u001b[39munfold(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcropsize, slide)\u001b[38;5;241m.\u001b[39munfold(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcropsize, slide)\n\u001b[1;32m    149\u001b[0m mask_crops\u001b[38;5;241m.\u001b[39munsqueeze(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.uint16. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "img_dir = \"/localscratch/project/data2d/norm_img/val/images/\"\n",
    "mask_dir = \"/localscratch/project/data2d/val_images2D/masks/\"\n",
    "testData = local.TestDataset(img_dir, mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d473d-e3b4-4b68-8999-39fa8485fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "testLoader = DataLoader(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2c96c-94b4-4e75-8b24-6aae9ae860dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in enumerate(testLoader):\n",
    "    image = image[0]\n",
    "    print(image.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee9d4a-98b6-4ffe-bdfb-6a6d16aa9f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
