{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to test the functions from train and the performance of the model on normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Union, List, Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import no_grad, cuda\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms.v2 as transforms_v2\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/localscratch/project/the_exceptionals/model\")\n",
    "from unet import UNet\n",
    "\n",
    "sys.path.append(\"/localscratch/project/the_exceptionals/util/\")\n",
    "from visualize import show_random_dataset_image_with_prediction\n",
    "\n",
    "sys.path.append(\"/localscratch/project/the_exceptionals/data/\")\n",
    "#from local import (\n",
    "#    CellDataset,\n",
    "#    show_random_dataset_image,\n",
    "#    show_one_image\n",
    "#)\n",
    "import local\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Global_normalize.__init__() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m img_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/localscratch/project/data2d/norm_img/train/images\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m mask_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/localscratch/project/data2d/train_images2D/masks\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomCrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localscratch/project/the_exceptionals/data/train.py:45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(img_dir, mask_dir, num_epochs, batch_size, shuffle, num_workers, depth, in_channels, out_channels, num_fmaps, transform)\u001b[0m\n\u001b[1;32m     40\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Import dataset\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#img_dir = \"/localscratch/exceptionals/train_images2D/images\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#mask_dir = \"/localscratch/exceptionals/train_images2D/masks\"\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m trainData \u001b[38;5;241m=\u001b[39m \u001b[43mlocal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCellDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmask_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mimg_transform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                       \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m     52\u001b[0m train_loader\u001b[38;5;241m=\u001b[39mDataLoader(trainData, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39mshuffle, num_workers\u001b[38;5;241m=\u001b[39mnum_workers)\n",
      "File \u001b[0;32m/localscratch/project/the_exceptionals/data/local.py:38\u001b[0m, in \u001b[0;36mCellDataset.__init__\u001b[0;34m(self, img_dir, mask_dir, transform, img_transform)\u001b[0m\n\u001b[1;32m     36\u001b[0m transform_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [transforms\u001b[38;5;241m.\u001b[39mGrayscale()]\n\u001b[1;32m     37\u001b[0m transform_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [transforms\u001b[38;5;241m.\u001b[39mToTensor()]\n\u001b[0;32m---> 38\u001b[0m transform_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mGlobal_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#transform_list += [transforms.Lambda(lambda  img: self.__normalize(img))]\u001b[39;00m\n\u001b[1;32m     40\u001b[0m inp_transforms \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose(transform_list)\n",
      "\u001b[0;31mTypeError\u001b[0m: Global_normalize.__init__() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "img_dir = \"/localscratch/project/data2d/norm_img/train/images\"\n",
    "mask_dir = \"/localscratch/project/data2d/train_images2D/masks\"\n",
    "\n",
    "train(img_dir, mask_dir, transform=transforms_v2.RandomCrop(256), num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
